{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install googletrans==4.0.0-rc1\n",
    "!pip install unicode\n",
    "!pip install pywin32\n",
    "!pip install pycountry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You must create a `.env` file containing the following paths:\n",
    "### Carpeta_Excel_Raw = Path to the folder containing raw Excel files\n",
    "### Carpeta_Nuevas_Extensiones = Folder where standardized files will be stored\n",
    "### Carpeta_Normalizado = Folder where normalized files will be stored\n",
    "### Carpeta_Consolidada = Folder where the consolidated file will be stored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing files into XLSX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from win32com.client import Dispatch\n",
    "import shutil\n",
    "import pythoncom\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "origen = Path(os.getenv(\"Carpeta_Excel_Raw\", \"\")).resolve()\n",
    "destino = Path(os.getenv(\"Carpeta_Nuevas_Extensiones\", \"\")).resolve()\n",
    "destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def convertir_y_copiar(origen: Path, destino: Path):\n",
    "    pythoncom.CoInitialize()\n",
    "    excel = Dispatch(\"Excel.Application\")\n",
    "    excel.DisplayAlerts = False  # <- Disables dialog boxes\n",
    "    \n",
    "    for archivo in origen.iterdir():\n",
    "        if archivo.suffix.lower() == \".xls\":\n",
    "            ruta = str(archivo)\n",
    "            nuevo = destino / (archivo.stem + \".xlsx\")\n",
    "            try:\n",
    "                # Opens in read-only mode to avoid modifying the original\n",
    "                wb = excel.Workbooks.Open(ruta, ReadOnly=True)\n",
    "                # Saves as .xlsx\n",
    "                wb.SaveAs(str(nuevo), FileFormat=51)\n",
    "                # Closes without saving changes to the .xls\n",
    "                wb.Close(SaveChanges=False)\n",
    "                print(f\"Converted: {archivo.name} ‚Üí {nuevo.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {archivo.name}: {e}\")\n",
    "        \n",
    "        elif archivo.suffix.lower() == \".xlsx\":\n",
    "            try:\n",
    "                shutil.copy2(str(archivo), str(destino / archivo.name))\n",
    "                print(f\"Copied: {archivo.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {archivo.name}: {e}\")\n",
    "    \n",
    "    excel.Quit()\n",
    "    pythoncom.CoUninitialize()\n",
    "\n",
    "# Runs the conversion\n",
    "convertir_y_copiar(origen, destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import pycountry_convert as pc\n",
    "import pycountry  # To get ISO codes\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "entrada = os.getenv(\"Carpeta_Nuevas_Extensiones\")\n",
    "salida  = os.getenv(\"Carpeta_Normalizado\")\n",
    "\n",
    "# Function to detect Japanese characters\n",
    "def contains_japanese(text):\n",
    "    for ch in str(text):\n",
    "        if ('\\u4e00' <= ch <= '\\u9fff') or ('\\u3040' <= ch <= '\\u309f') or ('\\u30a0' <= ch <= '\\u30ff'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to get continent from country using pycountry-convert\n",
    "def obtener_continente(pais):\n",
    "    try:\n",
    "        country_code   = pc.country_name_to_country_alpha2(pais, cn_name_format=\"default\")\n",
    "        continent_code = pc.country_alpha2_to_continent_code(country_code)\n",
    "        continents = {\n",
    "            \"AF\": \"Africa\", \"NA\": \"North America\", \"SA\": \"South America\",\n",
    "            \"AS\": \"Asia\",   \"EU\": \"Europe\",        \"OC\": \"Oceania\"\n",
    "        }\n",
    "        return continents.get(continent_code, \"Unknown\")\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Function to get ISO code of the country\n",
    "def obtener_codigo_iso(pais):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(pais).alpha_2\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "# Process each Excel file\n",
    "for nombre_archivo in os.listdir(entrada):\n",
    "    if not nombre_archivo.endswith(\".xlsx\"):\n",
    "        continue\n",
    "    try:\n",
    "        print(f\"Processing: {nombre_archivo}\")\n",
    "        ruta_entrada = os.path.join(entrada, nombre_archivo)\n",
    "        nombre_base  = os.path.splitext(nombre_archivo)[0].replace('_Normalizado', '')\n",
    "        ruta_salida  = os.path.join(salida, f\"{nombre_base}_Normalizado.xlsx\")\n",
    "\n",
    "        # Read the file without headers\n",
    "        df = pd.read_excel(ruta_entrada, header=None)\n",
    "\n",
    "        # 1) Remove column A and row 1\n",
    "        df = df.drop(columns=0).drop(index=0).reset_index(drop=True)\n",
    "\n",
    "        # 2) Remove columns in Japanese (2 and 3)\n",
    "        df = df.drop(columns=[2, 3], errors='ignore')\n",
    "\n",
    "        # 3) Trim from column ‚ÄúÂêàË®à‚Äù onwards (if it exists)\n",
    "        encabezado0 = df.iloc[0].astype(str).apply(lambda x: unicodedata.normalize(\"NFKC\", x))\n",
    "        if \"ÂêàË®à\" in list(encabezado0):\n",
    "            idx_total = list(encabezado0).index(\"ÂêàË®à\")\n",
    "            df = df.iloc[:, :idx_total]\n",
    "\n",
    "        # 4) Ensure a maximum of 14 columns\n",
    "        if df.shape[1] > 14:\n",
    "            df = df.iloc[:, :14]\n",
    "\n",
    "        # 5) Replace Japanese labels ‚Üí English\n",
    "        df = df.replace({'ÂøúÂãüËÄÖ': 'Applicant', 'ÂèóÈ®ìËÄÖ': 'Examinee'})\n",
    "\n",
    "        # 6) Prepare provisional headers\n",
    "        encabezados = [unicodedata.normalize(\"NFKC\", str(e)) for e in df.iloc[0].tolist()]\n",
    "\n",
    "        # 7) Generate list of new column names\n",
    "        niveles = ['N1', 'N2', 'N3', 'N4', 'N5']\n",
    "        nuevas_columnas = ['Country/Region', 'City (ENG)']\n",
    "        i = 2\n",
    "        for nivel in niveles:\n",
    "            if i + 1 < len(encabezados):\n",
    "                nuevas_columnas += [f\"{nivel} Applicants\", f\"{nivel} Examinees\"]\n",
    "                i += 2\n",
    "\n",
    "        # 8) Assign new headers and remove the title row\n",
    "        df.columns = nuevas_columnas\n",
    "        df = df.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "        # 9) Clean Country/Region from Japanese text\n",
    "        for idx, val in df['Country/Region'].items():\n",
    "            if contains_japanese(val) and (idx + 1) in df.index:\n",
    "                df.at[idx, 'Country/Region'] = unicodedata.normalize(\n",
    "                    'NFKC', str(df.at[idx + 1, 'Country/Region'])\n",
    "                )\n",
    "        df['Country/Region'] = (\n",
    "            df['Country/Region']\n",
    "              .astype(str)\n",
    "              .apply(lambda x: unicodedata.normalize('NFKC', x))\n",
    "              .apply(lambda x: None if contains_japanese(x) else x)\n",
    "        )\n",
    "        df['Country/Region'] = df['Country/Region'].replace('nan', pd.NA).fillna(method='ffill')\n",
    "\n",
    "        # 10) Filter valid rows: remove rows without City (ENG)\n",
    "        df = df[df['Country/Region'].notna()]\n",
    "        df = df[df['City (ENG)'].notna() & (df['City (ENG)'].astype(str).str.strip() != '')]\n",
    "\n",
    "        # 11) Pivot to long format\n",
    "        df_long = df.melt(\n",
    "            id_vars=['Country/Region', 'City (ENG)'],\n",
    "            var_name='metric',\n",
    "            value_name='Count'\n",
    "        )\n",
    "        df_long[['Level', 'Type']] = df_long['metric'].str.split(' ', expand=True)\n",
    "        df_long = df_long.drop(columns=['metric'])\n",
    "\n",
    "        # 12) Add columns: Date, Year, Month\n",
    "        parts = nombre_base.split('_')\n",
    "        year = int(parts[0])\n",
    "        mid = int(parts[1])\n",
    "        fecha = pd.Timestamp(year, mid, 1).date()\n",
    "        df_long['Fecha'] = fecha\n",
    "        df_long['A√±o'] = year\n",
    "        df_long['Mes'] = 'July' if mid == 1 else ('December' if mid == 2 else '')\n",
    "\n",
    "        # Additional cleanup: remove extra whitespace\n",
    "        df_long['Country/Region'] = df_long['Country/Region'].astype(str).str.strip()\n",
    "\n",
    "        # üÜï Manual replacements of problematic names (before getting ISO codes)\n",
    "        reemplazos_paises = {\n",
    "            \"Brunei\": \"Brunei Darussalam\",\n",
    "            \"Russia\": \"Russian Federation\",\n",
    "            \"Turkey\": \"T√ºrkiye\",\n",
    "            \"Korea\": \"South Korea\",\n",
    "            \"Ivory Coast\": \"C√¥te d'Ivoire\",\n",
    "            \"Cote d' Ivoire\": \"C√¥te d'Ivoire\",\n",
    "            \"Cote d'Ivoire\": \"C√¥te d'Ivoire\",\n",
    "            \"DR Congo\": \"Congo, The Democratic Republic of the\",\n",
    "            \"Democratic Republic of the Congo\": \"Congo, The Democratic Republic of the\",\n",
    "            \"Mongol\": \"Mongolia\",\n",
    "            \"U.S.A.\": \"United States\",\n",
    "            \"U.K.\": \"United Kingdom\",\n",
    "            \"Czech\": \"Czech Republic\",\n",
    "            \"Catarrh\": \"Qatar\"\n",
    "        }\n",
    "        df_long['Country/Region'] = df_long['Country/Region'].replace(reemplazos_paises)\n",
    "\n",
    "        # 13) Concatenate and classify by continent\n",
    "        df_long['City & Country/ Region'] = df_long['City (ENG)'] + ', ' + df_long['Country/Region']\n",
    "        df_long['Continent'] = df_long['Country/Region'].apply(obtener_continente)\n",
    "\n",
    "        # 14) Add ISO country code and flag URL\n",
    "        df_long['Country Code'] = df_long['Country/Region'].apply(obtener_codigo_iso)\n",
    "        df_long['Flag URL'] = df_long['Country Code'].apply(\n",
    "            lambda code: f\"https://flagcdn.com/w40/{code.lower()}.png\" if pd.notna(code) else None\n",
    "        )\n",
    "\n",
    "        # Save result\n",
    "        df_long.to_excel(ruta_salida, index=False)\n",
    "        print(f\"‚úî Saved: {ruta_salida}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {nombre_archivo}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "ruta_entrada = os.getenv(\"Carpeta_Normalizado\")\n",
    "ruta_salida  = os.getenv(\"Carpeta_Consolidada\")\n",
    "nombre_salida = \"JLPT_Historico.xlsx\"\n",
    "\n",
    "if not ruta_entrada or not ruta_salida:\n",
    "    raise RuntimeError(\"Error: Input or output paths are not defined in the .env file\")\n",
    "\n",
    "# Collect all DataFrames\n",
    "dataframes = []\n",
    "for archivo in os.listdir(ruta_entrada):\n",
    "    # Skip OneDrive temporary files and any non-Excel files\n",
    "    if not archivo.endswith(\".xlsx\") or archivo.startswith(\"~$\"):\n",
    "        continue\n",
    "\n",
    "    ruta_archivo = os.path.join(ruta_entrada, archivo)\n",
    "    try:\n",
    "        df = pd.read_excel(ruta_archivo)\n",
    "    except Exception as e:\n",
    "        print(f\"‚úò Could not read '{archivo}': {e}\")\n",
    "        continue\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n",
    "if not dataframes:\n",
    "    raise RuntimeError(\"No valid files found for consolidation.\")\n",
    "\n",
    "# Concatenate without altering columns\n",
    "df_consolidado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Ensure 'Fecha' column is date only (no time)\n",
    "if 'Fecha' in df_consolidado.columns:\n",
    "    # Convert to datetime if not already, then extract date part only\n",
    "    df_consolidado['Fecha'] = pd.to_datetime(df_consolidado['Fecha']).dt.date\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(ruta_salida, exist_ok=True)\n",
    "ruta_salida_completa = os.path.join(ruta_salida, nombre_salida)\n",
    "\n",
    "# Save the consolidated file\n",
    "with pd.ExcelWriter(ruta_salida_completa, engine=\"openpyxl\") as writer:\n",
    "    df_consolidado.to_excel(writer, index=False, sheet_name=\"JLPT_Historico\")\n",
    "    # Auto-adjust column widths\n",
    "    worksheet = writer.sheets[\"JLPT_Historico\"]\n",
    "    for col_cells in worksheet.columns:\n",
    "        max_length = max(len(str(cell.value)) for cell in col_cells)\n",
    "        col_letter = col_cells[0].column_letter\n",
    "        worksheet.column_dimensions[col_letter].width = max_length + 2\n",
    "\n",
    "print(f\"‚úî Consolidated file saved at: {ruta_salida_completa}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
